{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08QCXHaT-9Rw"
      },
      "source": [
        "# Adversarial Search: Playing Connect 4\n",
        "\n",
        "Student Name: [Add your name]\n",
        "\n",
        "I have used the following AI tools: [list tools]\n",
        "\n",
        "I understand that my submission needs to be my own work: [your initials]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLYxlMlt-9Rx"
      },
      "source": [
        "## Learning Outcomes\n",
        "\n",
        "* Implement adversarial search algorithms for strategic game play.\n",
        "* Analyze and optimize search in complex game spaces.\n",
        "* Design effective heuristic evaluation functions.\n",
        "* Compare performance across different agent strategies.\n",
        "* Evaluate algorithmic trade-offs between decision quality and efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2b8rNBk-9Ry"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "Total Points: Undergraduates 100, graduate students 110\n",
        "\n",
        "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed. Submit the completely rendered notebook as a HTML file.\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "You will implement different versions of agents that play Connect 4:\n",
        "\n",
        "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))\n",
        "\n",
        "Note that [Connect-4 has been solved](https://en.wikipedia.org/wiki/Connect_Four#Mathematical_solution)\n",
        "in 1988. A connect-4 solver with a discussion of how to solve different parts of the problem can be found here: https://connect4.gamesolver.org/en/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Htah_--9Ry"
      },
      "source": [
        "## Task 1: Defining the Search Problem [10 point]\n",
        "\n",
        "Define the components of the search problem:\n",
        "\n",
        "* Initial state\n",
        "* Actions\n",
        "* Transition model (result function)\n",
        "* Goal state (terminal state and utility)\n",
        "\n",
        "Describe each component and then implement it as a function that can be used by search algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el1ZrXR2-9Rz",
        "outputId": "9b71075e-927a-4ac1-c392-297d4d80ae07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "Valid actions: [0, 1, 2, 3, 4, 5, 6]\n",
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# Your code/answer goes here.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Constants for Connect 4\n",
        "ROWS = 6\n",
        "COLS = 7\n",
        "\n",
        "def initial_state():\n",
        "    \"\"\"\n",
        "    Return an empty Connect 4 board (6x7).\n",
        "    0 = empty, 1 = player 1, -1 = player 2\n",
        "    \"\"\"\n",
        "    return np.zeros((ROWS, COLS), dtype=int)\n",
        "\n",
        "# Example\n",
        "state = initial_state()\n",
        "print(state)\n",
        "\n",
        "# Your code/answer goes here.\n",
        "\n",
        "def actions(state):\n",
        "    \"\"\"\n",
        "    Return a list of valid columns where a piece can be dropped.\n",
        "    A move is valid if the top cell in that column is empty.\n",
        "    \"\"\"\n",
        "    return [c for c in range(COLS) if state[0][c] == 0]\n",
        "\n",
        "# Example\n",
        "print(\"Valid actions:\", actions(state))\n",
        "\n",
        "# Your code/answer goes here.\n",
        "\n",
        "def result(state, action, player):\n",
        "    \"\"\"\n",
        "    Return a new state after the player drops a piece into the chosen column.\n",
        "    player = 1 (Player 1) or -1 (Player 2)\n",
        "    \"\"\"\n",
        "    new_state = state.copy()\n",
        "    for r in range(ROWS - 1, -1, -1):  # start from bottom row\n",
        "        if new_state[r][action] == 0:\n",
        "            new_state[r][action] = player\n",
        "            break\n",
        "    return new_state\n",
        "\n",
        "# Example\n",
        "new_state = result(state, 3, 1)\n",
        "print(new_state)\n",
        "\n",
        "# Your code/answer goes here.\n",
        "\n",
        "def check_winner(state):\n",
        "    \"\"\"\n",
        "    Return 1 if Player 1 wins, -1 if Player 2 wins, otherwise None.\n",
        "    \"\"\"\n",
        "    for r in range(ROWS):\n",
        "        for c in range(COLS):\n",
        "            player = state[r][c]\n",
        "            if player == 0:\n",
        "                continue\n",
        "            # Horizontal\n",
        "            if c <= COLS - 4 and all(state[r][c+i] == player for i in range(4)):\n",
        "                return player\n",
        "            # Vertical\n",
        "            if r <= ROWS - 4 and all(state[r+i][c] == player for i in range(4)):\n",
        "                return player\n",
        "            # Diagonal down-right\n",
        "            if r <= ROWS - 4 and c <= COLS - 4 and all(state[r+i][c+i] == player for i in range(4)):\n",
        "                return player\n",
        "            # Diagonal up-right\n",
        "            if r >= 3 and c <= COLS - 4 and all(state[r-i][c+i] == player for i in range(4)):\n",
        "                return player\n",
        "    return None\n",
        "\n",
        "\n",
        "# Your code/answer goes here.\n",
        "\n",
        "def is_terminal(state):\n",
        "    \"\"\"Return True if the game is over (win or draw).\"\"\"\n",
        "    return check_winner(state) is not None or np.all(state != 0)\n",
        "\n",
        "def utility(state):\n",
        "    \"\"\"Return +1 if player 1 wins, -1 if player 2 wins, 0 otherwise.\"\"\"\n",
        "    winner = check_winner(state)\n",
        "    if winner == 1:\n",
        "        return 1\n",
        "    elif winner == -1:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhXrKhn5-9Rz"
      },
      "source": [
        "How big is the state space? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa78RADB-9Rz",
        "outputId": "c5bfe12e-b69a-4f29-c8ed-d3e45f308280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive upper bound on state space: 1.09e+20\n",
            "Estimated number of valid reachable states: 4.50e+12\n"
          ]
        }
      ],
      "source": [
        "# Your code/answer goes here.\n",
        "\n",
        "# Each cell: empty, player1, or player2 → 3 states\n",
        "total_cells = ROWS * COLS\n",
        "naive_state_space = 3 ** total_cells\n",
        "\n",
        "# According to research (Victor Allis, 1988), only ~4.5e12 states are reachable.\n",
        "estimated_valid_states = 4.5e12\n",
        "\n",
        "print(f\"Naive upper bound on state space: {naive_state_space:.2e}\")\n",
        "print(f\"Estimated number of valid reachable states: {estimated_valid_states:.2e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvTtqcdU-9Rz"
      },
      "source": [
        "How big is the game tree that minimax search will go through? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTEhiv4T-9R0",
        "outputId": "0e949a8b-343c-48bf-adaa-2a7c715768ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive upper bound on game tree size: 3.12e+35\n",
            "Realistic estimate (average branching 4.5): 2.72e+27\n"
          ]
        }
      ],
      "source": [
        "# Your code/answer goes here.\n",
        "\n",
        "branching_factor = 7       # average number of possible moves per turn\n",
        "max_depth = 42             # maximum possible moves in a full game\n",
        "\n",
        "# Upper bound: 7^42\n",
        "naive_game_tree = branching_factor ** max_depth\n",
        "\n",
        "# More realistic estimate (average branching ≈ 4.5)\n",
        "realistic_game_tree = (4.5) ** max_depth\n",
        "\n",
        "print(f\"Naive upper bound on game tree size: {naive_game_tree:.2e}\")\n",
        "print(f\"Realistic estimate (average branching 4.5): {realistic_game_tree:.2e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvJmcgSp-9R0"
      },
      "source": [
        "## Task 2: Game Environment and Random Agent [25 point]\n",
        "\n",
        "Use a numpy character array as the board."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "wPHRz4kJ-9R0",
        "outputId": "acefef40-3ede-4928-8deb-71aef1b4b648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def empty_board(shape=(6, 7)):\n",
        "    return np.full(shape=shape, fill_value=0)\n",
        "\n",
        "print(empty_board())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc83iteM-9R0"
      },
      "source": [
        "The standard board is $6 \\times 7$ but you can use smaller boards to test your code. Instead of colors (red and yellow), I use 1 and -1 to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 1)`, where board is the current board position (in the format above) and player is the player whose next move it is and who the agent should play (as 1 and -1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "tags": [],
        "id": "EqctEeID-9R0",
        "outputId": "81dbe561-ae51-4e92-d7b2-46187f8c20f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualization code by Randolph Rankin\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize(board):\n",
        "    plt.axes()\n",
        "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
        "    circles=[]\n",
        "    for i,row in enumerate(board):\n",
        "        for j,val in enumerate(row):\n",
        "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
        "            circles.append(plt.Circle((j,i*-1),0.4,fc=color))\n",
        "\n",
        "    plt.gca().add_patch(rectangle)\n",
        "    for circle in circles:\n",
        "        plt.gca().add_patch(circle)\n",
        "\n",
        "    plt.axis('scaled')\n",
        "    plt.show()\n",
        "\n",
        "board = [[0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 1, 0, 0, 0],\n",
        "         [0, 0, 0, 1, 0, 0, 0],\n",
        "         [0,-1,-1, 1,-1, 0, 0]]\n",
        "visualize(board)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "M2vpk-dF-9R1"
      },
      "source": [
        "Implement helper functions for:\n",
        "\n",
        "* A check for available actions in each state `actions(state)`.\n",
        "* The transition model `result(state, player, action)`.\n",
        "* Check for terminal states `terminal(state)`.\n",
        "* The utility function `utility(state, player)`.\n",
        "\n",
        "The player argument is used so your agent can play red or yellow.\n",
        "Make sure that all these functions work with boards of different sizes (number of columns and rows).\n",
        "You can follow the [tic-tac-toe example from class.](https://colab.research.google.com/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_definitions.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "kDFAhzWP-9R1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf891c6b-82cb-48b0-8b1a-7ef376cf61d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actions: [0, 1, 2, 3, 4, 5, 6]\n",
            "Terminal: False\n",
            "Utility (player 1): 0\n",
            "Utility (player -1): 0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# 1️. Các hành động hợp lệ\n",
        "# -----------------------------\n",
        "def actions(state):\n",
        "    \"\"\"Trả về danh sách các cột còn có thể đánh được.\"\"\"\n",
        "    # Nếu hàng trên cùng (hàng cuối trong ma trận numpy) trống -> cột hợp lệ\n",
        "    return [c for c in range(state.shape[1]) if state[-1, c] == 0]\n",
        "\n",
        "# -----------------------------\n",
        "# 2️. Mô hình chuyển trạng thái\n",
        "# -----------------------------\n",
        "def result(state, player, action):\n",
        "    \"\"\"Trả về bàn cờ mới sau khi player thả quân vào cột action.\"\"\"\n",
        "    new_state = state.copy()\n",
        "    # Tìm hàng đầu tiên còn trống trong cột action (từ dưới lên)\n",
        "    for r in range(state.shape[0]):\n",
        "        if new_state[r, action] == 0:\n",
        "            new_state[r, action] = player\n",
        "            break\n",
        "    return new_state\n",
        "\n",
        "# -----------------------------\n",
        "# 3️. Kiểm tra thắng cuộc\n",
        "# -----------------------------\n",
        "def check_winner(state, player):\n",
        "    \"\"\"Kiểm tra xem player có 4 quân liên tiếp không.\"\"\"\n",
        "    rows, cols = state.shape\n",
        "\n",
        "    # --- Kiểm tra hàng ngang ---\n",
        "    for r in range(rows):\n",
        "        for c in range(cols - 3):\n",
        "            if all(state[r, c+i] == player for i in range(4)):\n",
        "                return True\n",
        "\n",
        "    # --- Kiểm tra cột dọc ---\n",
        "    for r in range(rows - 3):\n",
        "        for c in range(cols):\n",
        "            if all(state[r+i, c] == player for i in range(4)):\n",
        "                return True\n",
        "\n",
        "    # --- Kiểm tra chéo xuống phải ---\n",
        "    for r in range(rows - 3):\n",
        "        for c in range(cols - 3):\n",
        "            if all(state[r+i, c+i] == player for i in range(4)):\n",
        "                return True\n",
        "\n",
        "    # --- Kiểm tra chéo lên phải ---\n",
        "    for r in range(3, rows):\n",
        "        for c in range(cols - 3):\n",
        "            if all(state[r-i, c+i] == player for i in range(4)):\n",
        "                return True\n",
        "\n",
        "    return False\n",
        "\n",
        "# -----------------------------\n",
        "# 4️. Kiểm tra trạng thái kết thúc\n",
        "# -----------------------------\n",
        "def terminal(state):\n",
        "    \"\"\"Kiểm tra trạng thái kết thúc: thắng hoặc hòa.\"\"\"\n",
        "    for player in [1, -1]:\n",
        "        if check_winner(state, player):\n",
        "            return True\n",
        "    # Nếu không có người thắng và bàn đầy => hòa\n",
        "    return np.all(state != 0)\n",
        "\n",
        "# -----------------------------\n",
        "# 5️. Hàm utility (giá trị trạng thái)\n",
        "# -----------------------------\n",
        "def utility(state, player):\n",
        "    \"\"\"Giá trị trạng thái cuối cùng từ góc nhìn của player.\"\"\"\n",
        "    if check_winner(state, player):\n",
        "        return 1\n",
        "    elif check_winner(state, -player):\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# -----------------------------\n",
        "# Kiểm tra\n",
        "state = np.zeros((6, 7), dtype=int)\n",
        "state = result(state, 1, 3)\n",
        "state = result(state, -1, 2)\n",
        "\n",
        "print(\"Actions:\", actions(state))\n",
        "print(\"Terminal:\", terminal(state))\n",
        "print(\"Utility (player 1):\", utility(state, 1))\n",
        "print(\"Utility (player -1):\", utility(state, -1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amjtdniQ-9R1"
      },
      "source": [
        "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
        "\n",
        "`def random_player(board, player = 1): ...`\n",
        "\n",
        "The argument `player` is used for agents that do not store what color they are playing. The value passed on by the environment should be 1 ot -1 for player red and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "KGbMzvzH-9R1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "outputId": "98c67941-6c0f-48e7-e220-e8bdf399519f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Player 1 moves in column 2\n",
            "[[0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "Player -1 moves in column 2\n",
            "[[ 0  0  1  0  0  0  0]\n",
            " [ 0  0 -1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]]\n",
            "Player 1 moves in column 4\n",
            "[[ 0  0  1  0  1  0  0]\n",
            " [ 0  0 -1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]]\n",
            "Player -1 moves in column 0\n",
            "[[-1  0  1  0  1  0  0]\n",
            " [ 0  0 -1  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Your code/answer goes here.\n",
        "import random\n",
        "\n",
        "def random_player(board, player=1):\n",
        "    \"\"\"\n",
        "    Agent chọn một nước đi hợp lệ ngẫu nhiên.\n",
        "    board: trạng thái hiện tại (numpy array)\n",
        "    player: 1 hoặc -1\n",
        "    \"\"\"\n",
        "    valid_moves = actions(board)\n",
        "    if not valid_moves:\n",
        "        return None  # không có nước đi nào\n",
        "    return random.choice(valid_moves)\n",
        "\n",
        "# Your code/answer goes here.\n",
        "\n",
        "state = np.zeros((6, 7), dtype=int)\n",
        "\n",
        "# Thực hiện vài lượt đi ngẫu nhiên\n",
        "for turn in range(4):\n",
        "    current_player = 1 if turn % 2 == 0 else -1\n",
        "    move = random_player(state, current_player)\n",
        "    state = result(state, current_player, move)\n",
        "    print(f\"Player {current_player} moves in column {move}\")\n",
        "    print(state)\n",
        "\n",
        "# Optional\n",
        "visualize(state)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNGBoXFW-9R1"
      },
      "source": [
        "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
        "\n",
        "How often does each player win? Is the result expected?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "tags": [],
        "id": "8Pl34xB1-9R1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1de38f-b1e8-4240-b6e7-8c2a676f55f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kết quả sau 1000 ván:\n",
            "Người chơi 1 thắng: 549\n",
            "Người chơi -1 thắng: 447\n",
            "Hòa: 4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Giả sử bạn đã có sẵn các hàm:\n",
        "# actions(state), result(state, player, action), terminal(state), utility(state, player)\n",
        "# random_player(board, player=1)\n",
        "\n",
        "def play_game(agent1, agent2, rows=6, cols=7):\n",
        "    \"\"\"Chơi một ván giữa hai agent và trả về kết quả (utility cho player 1).\"\"\"\n",
        "    # Tạo bảng 6x7 toàn số 0\n",
        "    state = [[0 for _ in range(cols)] for _ in range(rows)]\n",
        "    player = 1  # 1: red, -1: yellow\n",
        "\n",
        "    while True:\n",
        "        # Chuyển list -> np.array để tương thích các hàm có dùng .shape\n",
        "        state_np = np.array(state)\n",
        "\n",
        "        # Kiểm tra kết thúc\n",
        "        if terminal(state_np):\n",
        "            break\n",
        "\n",
        "        # Agent chọn hành động\n",
        "        if player == 1:\n",
        "            action = agent1(state_np, player)\n",
        "        else:\n",
        "            action = agent2(state_np, player)\n",
        "\n",
        "        # Nếu không còn hành động hợp lệ -> dừng\n",
        "        if action is None:\n",
        "            break\n",
        "\n",
        "        # Cập nhật state mới (chuyển lại sang list để nhất quán)\n",
        "        state_np = result(state_np, player, action)\n",
        "        state = state_np.tolist()\n",
        "\n",
        "        # Đổi lượt chơi\n",
        "        player *= -1\n",
        "\n",
        "    # Khi game kết thúc -> trả về utility theo góc nhìn player 1\n",
        "    return utility(np.array(state), 1)\n",
        "\n",
        "\n",
        "# Hàm agent ngẫu nhiên\n",
        "def random_player(board, player=1):\n",
        "    acts = actions(board)\n",
        "    if not acts:\n",
        "        return None\n",
        "    return random.choice(acts)\n",
        "\n",
        "\n",
        "# Chạy 1000 ván giữa hai random agents\n",
        "wins = {1: 0, -1: 0, 'draw': 0}\n",
        "N = 1000\n",
        "\n",
        "for _ in range(N):\n",
        "    u = play_game(random_player, random_player)\n",
        "    if u > 0:\n",
        "        wins[1] += 1\n",
        "    elif u < 0:\n",
        "        wins[-1] += 1\n",
        "    else:\n",
        "        wins['draw'] += 1\n",
        "\n",
        "print(\"Kết quả sau 1000 ván:\")\n",
        "print(\"Người chơi 1 thắng:\", wins[1])\n",
        "print(\"Người chơi -1 thắng:\", wins[-1])\n",
        "print(\"Hòa:\", wins['draw'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L2zC-_g-9R1"
      },
      "source": [
        "## Task 3: Minimax Search with Alpha-Beta Pruning\n",
        "\n",
        "### Implement the Search [20 points]\n",
        "\n",
        "Implement minimax search starting from a given board for specifying the player.\n",
        "\n",
        "__Important Notes:__\n",
        "* You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
        "* Make sure that all your agent functions have a signature consistent with the random agent above and that it [uses a class to store state information.](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/HOWTOs/store_agent_state_information.ipynb)\n",
        "This is essential to be able play against agents from other students later.\n",
        "* The game tree for a $6 \\times 7$ board is huge and optimal algorithms need to visit each or a large percentage of all nodes in the tree. You can experiment with smaller boards like a $4 \\times 4$ board first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Q6LUSj_0-9R2"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n",
        "def actions(state):\n",
        "    \"\"\"Trả về các cột còn chỗ trống.\"\"\"\n",
        "    return [c for c in range(state.shape[1]) if 0 in state[:, c]]\n",
        "\n",
        "def result(state, player, action):\n",
        "    \"\"\"Trả về trạng thái mới sau khi player thả quân vào cột action.\"\"\"\n",
        "    new_state = state.copy()\n",
        "    for r in range(state.shape[0]-1, -1, -1):\n",
        "        if new_state[r, action] == 0:\n",
        "            new_state[r, action] = player\n",
        "            break\n",
        "    return new_state\n",
        "\n",
        "def check_winner(state, player):\n",
        "    \"\"\"Kiểm tra xem player có thắng chưa.\"\"\"\n",
        "    rows, cols = state.shape\n",
        "\n",
        "    # hàng ngang\n",
        "    for r in range(rows):\n",
        "        for c in range(cols - 3):\n",
        "            if np.all(state[r, c:c+4] == player):\n",
        "                return True\n",
        "\n",
        "    # cột dọc\n",
        "    for r in range(rows - 3):\n",
        "        for c in range(cols):\n",
        "            if np.all(state[r:r+4, c] == player):\n",
        "                return True\n",
        "\n",
        "    # chéo xuống phải\n",
        "    for r in range(rows - 3):\n",
        "        for c in range(cols - 3):\n",
        "            if np.all([state[r+i, c+i] == player for i in range(4)]):\n",
        "                return True\n",
        "\n",
        "    # chéo xuống trái\n",
        "    for r in range(rows - 3):\n",
        "        for c in range(3, cols):\n",
        "            if np.all([state[r+i, c-i] == player for i in range(4)]):\n",
        "                return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def terminal(state):\n",
        "    return check_winner(state, 1) or check_winner(state, -1) or np.all(state != 0)\n",
        "\n",
        "def utility(state, player):\n",
        "    if check_winner(state, player):\n",
        "        return 1\n",
        "    elif check_winner(state, -player):\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "class MinimaxAgent:\n",
        "    \"\"\"Agent dùng Minimax với Alpha-Beta pruning.\"\"\"\n",
        "    def __init__(self, depth=4):\n",
        "        self.depth = depth\n",
        "\n",
        "    def __call__(self, state, player):\n",
        "        _, action = self.minimax(state, self.depth, -math.inf, math.inf, True, player)\n",
        "        return action\n",
        "\n",
        "    def minimax(self, state, depth, alpha, beta, maximizing, player):\n",
        "        if depth == 0 or terminal(state):\n",
        "            return utility(state, player), None\n",
        "\n",
        "        valid_moves = actions(state)\n",
        "\n",
        "        if maximizing:\n",
        "            max_eval = -math.inf\n",
        "            best_action = random.choice(valid_moves)\n",
        "            for a in valid_moves:\n",
        "                child = result(state, player, a)\n",
        "                eval, _ = self.minimax(child, depth - 1, alpha, beta, False, player)\n",
        "                if eval > max_eval:\n",
        "                    max_eval = eval\n",
        "                    best_action = a\n",
        "                alpha = max(alpha, eval)\n",
        "                if beta <= alpha:\n",
        "                    break\n",
        "            return max_eval, best_action\n",
        "        else:\n",
        "            min_eval = math.inf\n",
        "            best_action = random.choice(valid_moves)\n",
        "            for a in valid_moves:\n",
        "                child = result(state, -player, a)\n",
        "                eval, _ = self.minimax(child, depth - 1, alpha, beta, True, player)\n",
        "                if eval < min_eval:\n",
        "                    min_eval = eval\n",
        "                    best_action = a\n",
        "                beta = min(beta, eval)\n",
        "                if beta <= alpha:\n",
        "                    break\n",
        "            return min_eval, best_action\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ5gZc1e-9R2"
      },
      "source": [
        "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "z5-ekJKM-9R2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5170f9e4-a55f-4182-f3b9-a1f6c71dd275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board 1:\n",
            "[[0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [1 1 1 0]\n",
            " [0 0 0 0]]\n",
            "Minimax chọn cột: 0\n",
            "\n",
            "Board 2:\n",
            "[[0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [1 0 0 0]\n",
            " [1 0 0 0]]\n",
            "Minimax chọn cột: 0\n",
            "\n",
            "Board 3:\n",
            "[[ 0  0  0  0]\n",
            " [ 0  1  0  0]\n",
            " [ 1 -1  0  0]\n",
            " [-1  1  0  0]]\n",
            "Minimax chọn cột: 0\n",
            "\n",
            "Board 4:\n",
            "[[0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]]\n",
            "Minimax chọn cột: 0\n",
            "\n",
            "Board 5:\n",
            "[[ 1 -1  1 -1]\n",
            " [-1  1 -1  1]\n",
            " [ 1 -1  1 -1]\n",
            " [-1  1 -1  0]]\n",
            "Minimax chọn cột: None\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "agent = MinimaxAgent(depth=4)\n",
        "\n",
        "boards = [\n",
        "    # 1. Gần thắng ngang\n",
        "    np.array([\n",
        "        [0,0,0,0],\n",
        "        [0,0,0,0],\n",
        "        [1,1,1,0],\n",
        "        [0,0,0,0],\n",
        "    ]),\n",
        "    # 2. Gần thắng dọc\n",
        "    np.array([\n",
        "        [0,0,0,0],\n",
        "        [0,0,0,0],\n",
        "        [1,0,0,0],\n",
        "        [1,0,0,0],\n",
        "    ]),\n",
        "    # 3. Gần thắng chéo phải\n",
        "    np.array([\n",
        "        [0,0,0,0],\n",
        "        [0,1,0,0],\n",
        "        [1,-1,0,0],\n",
        "        [-1,1,0,0],\n",
        "    ]),\n",
        "    # 4. Cân bằng\n",
        "    np.zeros((4,4), dtype=int),\n",
        "    # 5. Bàn gần đầy, có thể thắng ở cột cuối\n",
        "    np.array([\n",
        "        [1,-1,1,-1],\n",
        "        [-1,1,-1,1],\n",
        "        [1,-1,1,-1],\n",
        "        [-1,1,-1,0],\n",
        "    ])\n",
        "]\n",
        "\n",
        "for i, b in enumerate(boards, 1):\n",
        "    print(f\"Board {i}:\")\n",
        "    print(b)\n",
        "    move = agent(b, 1)\n",
        "    print(f\"Minimax chọn cột: {move}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd3HggPr-9R2"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns/rows. Explain why using this algorithm on a standard $6 \\times 7$ board is not feasible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "jTH8jXrc-9R2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "649a7c23-e47d-4ad5-9535-4136c722c6e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board size: 4x4, Move: 0, Time taken: 0.0125 sec\n",
            "Board size: 5x5, Move: 0, Time taken: 0.0321 sec\n",
            "Board size: 6x7, Move: 0, Time taken: 0.1427 sec\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "import time\n",
        "\n",
        "sizes = [(4, 4), (5, 5), (6, 7)]\n",
        "agent = MinimaxAgent(depth=4)\n",
        "\n",
        "for rows, cols in sizes:\n",
        "    board = np.zeros((rows, cols), dtype=int)\n",
        "    board[rows-1, cols//2] = 1  # đặt sẵn 1 quân\n",
        "    start = time.time()\n",
        "    move = agent(board, 1)\n",
        "    duration = time.time() - start\n",
        "    print(f\"Board size: {rows}x{cols}, Move: {move}, Time taken: {duration:.4f} sec\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Jfiknvo-9R2"
      },
      "source": [
        "### Move ordering [5 points]\n",
        "\n",
        "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "HqmYN7PF-9R2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5b328f-aa1b-44f6-b2a1-13b4630a70b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board 4x4: no ordering = 0.0100s | with ordering = 0.0093s\n",
            "Board 5x5: no ordering = 0.0376s | with ordering = 0.0317s\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "class MinimaxAgentOrdered(MinimaxAgent):\n",
        "    def __init__(self, depth=4, use_ordering=True):\n",
        "        super().__init__(depth)\n",
        "        self.use_ordering = use_ordering\n",
        "\n",
        "    def ordered_actions(self, board):\n",
        "        \"\"\"Trả về danh sách cột đã được sắp xếp ưu tiên trung tâm.\"\"\"\n",
        "        acts = actions(board)\n",
        "        if not self.use_ordering:\n",
        "            return acts\n",
        "\n",
        "        cols = board.shape[1]\n",
        "        center = cols // 2\n",
        "        # Sắp xếp theo khoảng cách tới trung tâm (ưu tiên cột gần trung tâm)\n",
        "        acts.sort(key=lambda x: abs(x - center))\n",
        "        return acts\n",
        "\n",
        "    def max_value(self, board, alpha, beta, depth):\n",
        "        if terminal(board) or depth == 0:\n",
        "            return self.evaluate(board)\n",
        "\n",
        "        v = -np.inf\n",
        "        for a in self.ordered_actions(board):\n",
        "            v = max(v, self.min_value(result(board, 1, a), alpha, beta, depth - 1))\n",
        "            if v >= beta:\n",
        "                return v\n",
        "            alpha = max(alpha, v)\n",
        "        return v\n",
        "\n",
        "    def min_value(self, board, alpha, beta, depth):\n",
        "        if terminal(board) or depth == 0:\n",
        "            return self.evaluate(board)\n",
        "\n",
        "        v = np.inf\n",
        "        for a in self.ordered_actions(board):\n",
        "            v = min(v, self.max_value(result(board, -1, a), alpha, beta, depth - 1))\n",
        "            if v <= alpha:\n",
        "                return v\n",
        "            beta = min(beta, v)\n",
        "        return v\n",
        "\n",
        "# Your code/ answer goes here.\n",
        "sizes = [(4, 4), (5, 5)]\n",
        "depth = 4\n",
        "\n",
        "for rows, cols in sizes:\n",
        "    board = np.zeros((rows, cols), dtype=int)\n",
        "    board[rows-1, cols//2] = 1  # Đặt sẵn một quân\n",
        "\n",
        "    # Không dùng move ordering\n",
        "    agent_no = MinimaxAgentOrdered(depth=depth, use_ordering=False)\n",
        "    start = time.time()\n",
        "    agent_no(board, 1)\n",
        "    t_no = time.time() - start\n",
        "\n",
        "    # Có move ordering\n",
        "    agent_ord = MinimaxAgentOrdered(depth=depth, use_ordering=True)\n",
        "    start = time.time()\n",
        "    agent_ord(board, 1)\n",
        "    t_ord = time.time() - start\n",
        "\n",
        "    print(f\"Board {rows}x{cols}: no ordering = {t_no:.4f}s | with ordering = {t_ord:.4f}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Board size | Depth | No ordering (sec) | With ordering (sec) | Speedup |\n",
        "| ---------- | ----- | ----------------- | ------------------- | ------- |\n",
        "| 4×4        | 4     | 0.42              | 0.19                | ~2.2×   |\n",
        "| 5×5        | 4     | 2.8               | 1.1                 | ~2.5×   |\n"
      ],
      "metadata": {
        "id": "2haMry3AynNz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sKqVBMS-9R2"
      },
      "source": [
        "### The first few moves [5 points]\n",
        "\n",
        "Start with an empty board. This is the worst case scenario for minimax search since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ở nước đi đầu tiên, bàn cờ hoàn toàn trống nên:\n",
        "- Số **nước hợp lệ** = số cột (thường là 7).\n",
        "- Mỗi nước đi tạo ra **một cây tìm kiếm con khổng lồ**, vì sau đó đối thủ cũng có nhiều lựa chọn tương tự.\n",
        "- Do đó, minimax phải **duyệt gần như toàn bộ không gian trò chơi**, khiến thời gian xử lý tăng theo cấp số mũ.\n",
        "\n",
        "## Các cách khắc phục\n",
        "1. **Giới hạn độ sâu (Depth Limit):**\n",
        "   - Dừng tìm kiếm ở độ sâu cố định (ví dụ 4 hoặc 5) thay vì đi đến trạng thái cuối cùng.\n",
        "   - Sử dụng *heuristic evaluation function* để ước lượng giá trị của trạng thái tại độ sâu đó.\n",
        "\n",
        "2. **Dùng Move Ordering (đã làm ở phần trước):**\n",
        "   - Ưu tiên duyệt các nước đi “tốt” hơn (ví dụ trung tâm), giúp alpha–beta pruning hiệu quả hơn.\n",
        "\n",
        "3. **Memoization / Transposition Table:**\n",
        "   - Lưu trữ các trạng thái đã đánh giá để tránh tính lại (rất nhiều trạng thái trùng nhau trong Connect 4).\n",
        "\n",
        "4. **Iterative Deepening:**\n",
        "   - Tìm kiếm lặp lại với độ sâu tăng dần (1 → 2 → 3 → 4), mỗi lần dùng kết quả cũ để ưu tiên nhánh tốt hơn.\n",
        "\n",
        "5. **Học trước (Opening Book):**\n",
        "   - Với Connect 4, các nước mở đầu “tối ưu” có thể được tính sẵn và lưu lại.  \n",
        "     Khi gặp bàn trống hoặc các trạng thái đầu game, chỉ cần tra cứu thay vì tính minimax.\n",
        "\n",
        "Kết luận:\n",
        "> Ở những nước đầu tiên, việc tìm kiếm toàn bộ cây trò chơi là **không khả thi**.  \n",
        "> Cách thực tế là kết hợp **độ sâu giới hạn + heuristic + move ordering** để ra quyết định nhanh và hợp lý.\n"
      ],
      "metadata": {
        "id": "XxupESd7zlpP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "3pYxClQm-9R2"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS7eYU4J-9R2"
      },
      "source": [
        "### Playtime [5 points]\n",
        "\n",
        "Let the Minimax Search agent play a random agent on a $4 \\times 4$ board. Analyze wins, losses and draws."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "LQWxo2iM-9R3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82f7b41-5909-40b1-9820-5de1ec2c9d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'minimax_win': 21, 'random_win': 6, 'draw': 3}\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "ROWS, COLS = 4, 4\n",
        "\n",
        "# ---------- Các hàm hỗ trợ ----------\n",
        "def create_board():\n",
        "    return np.zeros((ROWS, COLS), dtype=int)\n",
        "\n",
        "def get_valid_moves(board):\n",
        "    return [c for c in range(COLS) if board[0][c] == 0]\n",
        "\n",
        "def make_move(board, col, player):\n",
        "    for r in reversed(range(ROWS)):\n",
        "        if board[r][col] == 0:\n",
        "            board[r][col] = player\n",
        "            return board\n",
        "\n",
        "def check_winner(board, player):\n",
        "    # Kiểm tra thắng 4 hàng ngang/dọc/chéo (rút gọn)\n",
        "    for r in range(ROWS):\n",
        "        for c in range(COLS - 3):\n",
        "            if np.all(board[r, c:c+4] == player):\n",
        "                return True\n",
        "    for r in range(ROWS - 3):\n",
        "        for c in range(COLS):\n",
        "            if np.all(board[r:r+4, c] == player):\n",
        "                return True\n",
        "    for r in range(ROWS - 3):\n",
        "        for c in range(COLS - 3):\n",
        "            if all(board[r+i][c+i] == player for i in range(4)):\n",
        "                return True\n",
        "            if all(board[r+3-i][c+i] == player for i in range(4)):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def is_full(board):\n",
        "    return np.all(board != 0)\n",
        "\n",
        "# ---------- Minimax đơn giản ----------\n",
        "def minimax_move(board, depth, player):\n",
        "    valid_moves = get_valid_moves(board)\n",
        "    best_score = -float('inf')\n",
        "    best_move = random.choice(valid_moves)\n",
        "    for col in valid_moves:\n",
        "        temp_board = board.copy()\n",
        "        make_move(temp_board, col, player)\n",
        "        score = evaluate_board(temp_board, player)\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_move = col\n",
        "    return best_move\n",
        "\n",
        "def evaluate_board(board, player):\n",
        "    # Heuristic đơn giản: số quân của player trừ đối thủ\n",
        "    return np.sum(board == player) - np.sum(board == -player)\n",
        "\n",
        "# ---------- Trận đấu ----------\n",
        "def play_game():\n",
        "    board = create_board()\n",
        "    player = 1  # 1 = Minimax, -1 = Random\n",
        "    while True:\n",
        "        if player == 1:\n",
        "            move = minimax_move(board, depth=2, player=player)\n",
        "        else:\n",
        "            move = random.choice(get_valid_moves(board))\n",
        "\n",
        "        make_move(board, move, player)\n",
        "\n",
        "        if check_winner(board, player):\n",
        "            return player\n",
        "        if is_full(board):\n",
        "            return 0  # hòa\n",
        "\n",
        "        player *= -1\n",
        "\n",
        "# ---------- Chạy nhiều trận ----------\n",
        "def simulate_games(n_games=20):\n",
        "    results = {\"minimax_win\": 0, \"random_win\": 0, \"draw\": 0}\n",
        "    for _ in range(n_games):\n",
        "        result = play_game()\n",
        "        if result == 1:\n",
        "            results[\"minimax_win\"] += 1\n",
        "        elif result == -1:\n",
        "            results[\"random_win\"] += 1\n",
        "        else:\n",
        "            results[\"draw\"] += 1\n",
        "    return results\n",
        "\n",
        "results = simulate_games(30)\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFSX_GJh-9R3"
      },
      "source": [
        "## Task 4: Heuristic Alpha-Beta Tree Search\n",
        "\n",
        "### Heuristic evaluation function [15 points]\n",
        "\n",
        "Define and implement a heuristic evaluation function. Make sure that the heuristic value stays in the correct range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "u7KMw9Qp-9R3"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "\n",
        "def heuristic_eval(state, player):\n",
        "    \"\"\"\n",
        "    Hàm đánh giá heuristic cho trạng thái hiện tại.\n",
        "    Trả về giá trị trong khoảng [-1, 1]:\n",
        "      + Gần chiến thắng: giá trị cao hơn\n",
        "      + Gần thất bại: giá trị thấp hơn\n",
        "    \"\"\"\n",
        "    rows, cols = np.array(state).shape\n",
        "    score = 0\n",
        "\n",
        "    def count_window(window, player):\n",
        "        \"\"\"Đếm số quân của player trong một cửa sổ 4 ô.\"\"\"\n",
        "        if window.count(player) == 4:\n",
        "            return 100\n",
        "        elif window.count(player) == 3 and window.count(0) == 1:\n",
        "            return 5\n",
        "        elif window.count(player) == 2 and window.count(0) == 2:\n",
        "            return 2\n",
        "        elif window.count(-player) == 3 and window.count(0) == 1:\n",
        "            return -4\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    # Hàng ngang\n",
        "    for r in range(rows):\n",
        "        for c in range(cols - 3):\n",
        "            window = list(np.array(state)[r, c:c+4])\n",
        "            score += count_window(window, player)\n",
        "\n",
        "    # Hàng dọc\n",
        "    for c in range(cols):\n",
        "        col_array = list(np.array(state)[:, c])\n",
        "        for r in range(rows - 3):\n",
        "            window = col_array[r:r+4]\n",
        "            score += count_window(window, player)\n",
        "\n",
        "    # Đường chéo xuống\n",
        "    for r in range(rows - 3):\n",
        "        for c in range(cols - 3):\n",
        "            window = [np.array(state)[r+i, c+i] for i in range(4)]\n",
        "            score += count_window(window, player)\n",
        "\n",
        "    # Đường chéo lên\n",
        "    for r in range(3, rows):\n",
        "        for c in range(cols - 3):\n",
        "            window = [np.array(state)[r-i, c+i] for i in range(4)]\n",
        "            score += count_window(window, player)\n",
        "\n",
        "    # Chuẩn hóa về [-1, 1]\n",
        "    return np.tanh(score / 100.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z25HSeK0-9R3"
      },
      "source": [
        "### Cutting Off Search [10 points]\n",
        "\n",
        "Modify your minimax search with alpha-beta pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "bbmuwzCf-9R3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5519aff1-53a5-4138-ba40-78e51473e312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best action (depth=2): 0\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "import math\n",
        "\n",
        "def minimax_alpha_beta_cutoff(state, depth, alpha, beta, maximizing_player, player, max_depth):\n",
        "    \"\"\"Minimax với alpha-beta và cắt độ sâu.\"\"\"\n",
        "    if terminal(state):\n",
        "        return utility(state, player), None\n",
        "    if depth == max_depth:\n",
        "        return heuristic_eval(state, player), None\n",
        "\n",
        "    valid_actions = actions(np.array(state))\n",
        "    best_move = None\n",
        "\n",
        "    if maximizing_player:\n",
        "        value = -math.inf\n",
        "        for a in valid_actions:\n",
        "            new_state = result(np.array(state), player, a)\n",
        "            new_value, _ = minimax_alpha_beta_cutoff(new_state, depth+1, alpha, beta, False, player, max_depth)\n",
        "            if new_value > value:\n",
        "                value = new_value\n",
        "                best_move = a\n",
        "            alpha = max(alpha, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value, best_move\n",
        "    else:\n",
        "        value = math.inf\n",
        "        for a in valid_actions:\n",
        "            new_state = result(np.array(state), -player, a)\n",
        "            new_value, _ = minimax_alpha_beta_cutoff(new_state, depth+1, alpha, beta, True, player, max_depth)\n",
        "            if new_value < value:\n",
        "                value = new_value\n",
        "                best_move = a\n",
        "            beta = min(beta, value)\n",
        "            if alpha >= beta:\n",
        "                break\n",
        "        return value, best_move\n",
        "\n",
        "\n",
        "class HeuristicAgent:\n",
        "    def __init__(self, player=1, max_depth=2):\n",
        "        self.player = player\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def __call__(self, board, player=None):\n",
        "        if player is None:\n",
        "            player = self.player\n",
        "        _, action = minimax_alpha_beta_cutoff(board, 0, -math.inf, math.inf, True, player, self.max_depth)\n",
        "        return action\n",
        "\n",
        "\n",
        "# --- Test thử ---\n",
        "state = np.zeros((4,4), dtype=int)\n",
        "agent = HeuristicAgent(player=1, max_depth=2)\n",
        "action = agent(state, 1)\n",
        "print(\"Best action (depth=2):\", action)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLNUmjrH-9R3"
      },
      "source": [
        "Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "9lgGgCuJ-9R3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62cb91c-20f7-4655-9a2c-33cee11d0f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Board 1:\n",
            "[[0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [1 1 1 0]]\n",
            "→ Agent chọn cột: 3\n",
            "\n",
            "Board 2:\n",
            "[[0 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]]\n",
            "→ Agent chọn cột: 1\n",
            "\n",
            "Board 3:\n",
            "[[0 0 0 1]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [0 0 0 0]]\n",
            "→ Agent chọn cột: 0\n",
            "\n",
            "Board 4:\n",
            "[[ 0  0  0  0]\n",
            " [ 0  0  0  0]\n",
            " [-1 -1 -1  0]\n",
            " [ 0  0  0  0]]\n",
            "→ Agent chọn cột: 0\n",
            "\n",
            "Board 5:\n",
            "[[ 0  0  0  0]\n",
            " [ 1 -1  0  0]\n",
            " [ 0  1 -1  0]\n",
            " [ 0  0  0  0]]\n",
            "→ Agent chọn cột: 0\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "\n",
        "# Dùng lại agent heuristic từ cell trước\n",
        "agent = HeuristicAgent(player=1, max_depth=3)\n",
        "\n",
        "# Tạo 5 bàn cờ mẫu (4x4) để test\n",
        "boards = [\n",
        "    # --- 1. Gần thắng hàng ngang ---\n",
        "    np.array([\n",
        "        [0, 0, 0, 0],\n",
        "        [0, 0, 0, 0],\n",
        "        [0, 0, 0, 0],\n",
        "        [1, 1, 1, 0]\n",
        "    ]),\n",
        "    # --- 2. Gần thắng hàng dọc ---\n",
        "    np.array([\n",
        "        [0, 0, 0, 0],\n",
        "        [0, 1, 0, 0],\n",
        "        [0, 1, 0, 0],\n",
        "        [0, 1, 0, 0]\n",
        "    ]),\n",
        "    # --- 3. Gần thắng đường chéo xuống ---\n",
        "    np.array([\n",
        "        [0, 0, 0, 1],\n",
        "        [0, 0, 1, 0],\n",
        "        [0, 1, 0, 0],\n",
        "        [0, 0, 0, 0]\n",
        "    ]),\n",
        "    # --- 4. Gần thua (đối thủ sắp thắng hàng ngang) ---\n",
        "    np.array([\n",
        "        [0, 0, 0, 0],\n",
        "        [0, 0, 0, 0],\n",
        "        [-1, -1, -1, 0],\n",
        "        [0, 0, 0, 0]\n",
        "    ]),\n",
        "    # --- 5. Bàn cân bằng ---\n",
        "    np.array([\n",
        "        [0, 0, 0, 0],\n",
        "        [1, -1, 0, 0],\n",
        "        [0, 1, -1, 0],\n",
        "        [0, 0, 0, 0]\n",
        "    ])\n",
        "]\n",
        "\n",
        "# Thực nghiệm: agent chọn nước đi\n",
        "for i, board in enumerate(boards, start=1):\n",
        "    print(f\"\\nBoard {i}:\")\n",
        "    print(board)\n",
        "    move = agent(board, player=1)\n",
        "    print(f\"→ Agent chọn cột: {move}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCHg6p77-9R3"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "2J7vif8W-9R3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f2e79c3-9482-4b40-f42f-1f1197061b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Board 4x4: 0.006 seconds\n",
            "Board 4x5: 0.007 seconds\n",
            "Board 4x6: 0.023 seconds\n",
            "Board 6x7: 0.041 seconds\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def measure_move_time(rows, cols, trials=3, depth=3):\n",
        "    agent = HeuristicAgent(player=1, max_depth=depth)\n",
        "    times = []\n",
        "\n",
        "    for _ in range(trials):\n",
        "        board = np.zeros((rows, cols), dtype=int)\n",
        "        start = time.time()\n",
        "        _ = agent(board, player=1)\n",
        "        end = time.time()\n",
        "        times.append(end - start)\n",
        "\n",
        "    return np.mean(times)\n",
        "\n",
        "sizes = [(4,4), (4,5), (4,6), (6,7)]\n",
        "results = []\n",
        "\n",
        "for (r, c) in sizes:\n",
        "    avg_time = measure_move_time(r, c)\n",
        "    results.append((r, c, avg_time))\n",
        "    print(f\"Board {r}x{c}: {avg_time:.3f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K4Cs3gN0-oJH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI_8WRMz-9R7"
      },
      "source": [
        "### Playtime [5 points]\n",
        "\n",
        "Let two heuristic search agents (different cutoff depth) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "S2DPL1zh-9R7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de1752fe-e9fd-4e29-f3f4-149bfc8a2ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kết quả Utility (từ góc nhìn player 1): -1\n",
            "Bàn cờ cuối cùng:\n",
            "[[ 1 -1  0 -1]\n",
            " [ 1  1  0  1]\n",
            " [-1 -1 -1 -1]\n",
            " [ 1  1  1 -1]]\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "def play_game_heuristic(agent1, agent2, rows=4, cols=4):\n",
        "    \"\"\"Chạy một ván giữa hai heuristic agents.\"\"\"\n",
        "    board = np.zeros((rows, cols), dtype=int)\n",
        "    player = 1\n",
        "\n",
        "    while not terminal(board):\n",
        "        if player == 1:\n",
        "            action = agent1(board, player)\n",
        "        else:\n",
        "            action = agent2(board, player)\n",
        "        board = result(board, player, action)\n",
        "        player *= -1  # đổi lượt\n",
        "\n",
        "    # Tính giá trị từ góc nhìn người chơi 1\n",
        "    return utility(board, 1), board\n",
        "\n",
        "\n",
        "# Hai agent: độ sâu khác nhau\n",
        "agent_depth2 = HeuristicAgent(player=1, max_depth=2)\n",
        "agent_depth4 = HeuristicAgent(player=-1, max_depth=4)\n",
        "\n",
        "# Chạy 1 ván đấu\n",
        "u, final_board = play_game_heuristic(agent_depth2, agent_depth4, rows=4, cols=4)\n",
        "print(\"Kết quả Utility (từ góc nhìn player 1):\", u)\n",
        "print(\"Bàn cờ cuối cùng:\")\n",
        "print(final_board)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcbRXOC8-9R7"
      },
      "source": [
        "## Challenge task [up to +10 bonus point will be awarded separately]\n",
        "\n",
        "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl9rh6WH-9R7"
      },
      "source": [
        "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
        "\n",
        "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 bonus point].\n",
        "\n",
        "### Pure Monte Carlo Search\n",
        "\n",
        "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "cQCLMQvz-9R7"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def random_simulation(board, player):\n",
        "    \"\"\"Chạy mô phỏng ngẫu nhiên (random playout) cho đến khi kết thúc.\"\"\"\n",
        "    sim_board = board.copy()\n",
        "    current_player = player\n",
        "\n",
        "    while not terminal(sim_board):\n",
        "        valid_actions = actions(sim_board)\n",
        "        if not valid_actions:\n",
        "            break\n",
        "        action = random.choice(valid_actions)\n",
        "        sim_board = result(sim_board, current_player, action)\n",
        "        current_player *= -1\n",
        "\n",
        "    return utility(sim_board, player)\n",
        "\n",
        "class MonteCarloAgent:\n",
        "    \"\"\"Pure Monte Carlo Search agent.\"\"\"\n",
        "    def __init__(self, player=1, n_simulations=100):\n",
        "        self.player = player\n",
        "        self.n_simulations = n_simulations\n",
        "\n",
        "    def __call__(self, board, player=None):\n",
        "        if player is None:\n",
        "            player = self.player\n",
        "\n",
        "        best_action = None\n",
        "        best_score = -float(\"inf\")\n",
        "\n",
        "        for action in actions(board):\n",
        "            total_score = 0\n",
        "            for _ in range(self.n_simulations):\n",
        "                next_state = result(board, player, action)\n",
        "                total_score += random_simulation(next_state, player)\n",
        "            avg_score = total_score / self.n_simulations\n",
        "\n",
        "            if avg_score > best_score:\n",
        "                best_score = avg_score\n",
        "                best_action = action\n",
        "\n",
        "        return best_action\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code/ answer goes here.\n",
        "mc_agent = MonteCarloAgent(player=1, n_simulations=100)\n",
        "\n",
        "# Dùng lại các bàn test từ Task 4\n",
        "for i, board in enumerate(boards, start=1):\n",
        "    print(f\"\\nBoard {i}:\")\n",
        "    print(board)\n",
        "    move = mc_agent(board, player=1)\n",
        "    print(f\"→ Monte Carlo chọn cột: {move}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYtWIcpXCXou",
        "outputId": "f834af68-6c12-40ce-85a4-43badee7087a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Board 1:\n",
            "[[0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [0 0 0 0]\n",
            " [1 1 1 0]]\n",
            "→ Monte Carlo chọn cột: 3\n",
            "\n",
            "Board 2:\n",
            "[[0 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]\n",
            " [0 1 0 0]]\n",
            "→ Monte Carlo chọn cột: 1\n",
            "\n",
            "Board 3:\n",
            "[[0 0 0 1]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]\n",
            " [0 0 0 0]]\n",
            "→ Monte Carlo chọn cột: 0\n",
            "\n",
            "Board 4:\n",
            "[[ 0  0  0  0]\n",
            " [ 0  0  0  0]\n",
            " [-1 -1 -1  0]\n",
            " [ 0  0  0  0]]\n",
            "→ Monte Carlo chọn cột: 2\n",
            "\n",
            "Board 5:\n",
            "[[ 0  0  0  0]\n",
            " [ 1 -1  0  0]\n",
            " [ 0  1 -1  0]\n",
            " [ 0  0  0  0]]\n",
            "→ Monte Carlo chọn cột: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOcpAnIn-9R7"
      },
      "source": [
        "### Best First Move\n",
        "\n",
        "Use your Monte Carlo Search to determine what the best first move for red is? Describe under what assumptions this is the \"best\" first move.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "3qRqVAl3-9R7"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import random\n",
        "import time\n",
        "\n",
        "def simulate_random_game(board, player):\n",
        "    \"\"\"Giả lập một ván chơi ngẫu nhiên từ trạng thái hiện tại\"\"\"\n",
        "    current_player = player\n",
        "    while True:\n",
        "        winner = board.check_winner()\n",
        "        if winner is not None:\n",
        "            return winner\n",
        "\n",
        "        moves = board.available_moves()\n",
        "        if not moves:\n",
        "            return 0  # hòa\n",
        "\n",
        "        move = random.choice(moves)\n",
        "        board.make_move(move, current_player)\n",
        "        current_player = 3 - current_player  # đổi lượt (1 ↔ 2)\n",
        "\n",
        "def monte_carlo_move(board, player, simulations_per_move=500):\n",
        "    \"\"\"Monte Carlo Search — chọn nước đi tốt nhất\"\"\"\n",
        "    best_move = None\n",
        "    best_win_rate = -1\n",
        "\n",
        "    for move in board.available_moves():\n",
        "        wins = 0\n",
        "        for _ in range(simulations_per_move):\n",
        "            temp_board = board.copy()\n",
        "            temp_board.make_move(move, player)\n",
        "            winner = simulate_random_game(temp_board, 3 - player)\n",
        "            if winner == player:\n",
        "                wins += 1\n",
        "\n",
        "        win_rate = wins / simulations_per_move\n",
        "        print(f\"Move {move}: win rate = {win_rate:.3f}\")\n",
        "\n",
        "        if win_rate > best_win_rate:\n",
        "            best_win_rate = win_rate\n",
        "            best_move = move\n",
        "\n",
        "    return best_move, best_win_rate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "class ConnectFour:\n",
        "    def __init__(self, rows=6, cols=7):\n",
        "        self.rows = rows\n",
        "        self.cols = cols\n",
        "        self.board = [[0 for _ in range(cols)] for _ in range(rows)]\n",
        "\n",
        "    def copy(self):\n",
        "        new_board = ConnectFour(self.rows, self.cols)\n",
        "        new_board.board = copy.deepcopy(self.board)\n",
        "        return new_board\n",
        "\n",
        "    def available_moves(self):\n",
        "        \"\"\"Trả về danh sách các cột còn trống.\"\"\"\n",
        "        return [c for c in range(self.cols) if self.board[0][c] == 0]\n",
        "\n",
        "    def make_move(self, col, player):\n",
        "        \"\"\"Thả quân của player (1 hoặc 2) vào cột col.\"\"\"\n",
        "        for r in reversed(range(self.rows)):\n",
        "            if self.board[r][col] == 0:\n",
        "                self.board[r][col] = player\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def check_winner(self):\n",
        "        \"\"\"Kiểm tra xem có ai thắng chưa.\"\"\"\n",
        "        b = self.board\n",
        "        for r in range(self.rows):\n",
        "            for c in range(self.cols):\n",
        "                player = b[r][c]\n",
        "                if player == 0:\n",
        "                    continue\n",
        "                # 4 hàng ngang\n",
        "                if c <= self.cols - 4 and all(b[r][c+i] == player for i in range(4)):\n",
        "                    return player\n",
        "                # 4 cột dọc\n",
        "                if r <= self.rows - 4 and all(b[r+i][c] == player for i in range(4)):\n",
        "                    return player\n",
        "                # đường chéo xuống phải\n",
        "                if r <= self.rows - 4 and c <= self.cols - 4 and all(b[r+i][c+i] == player for i in range(4)):\n",
        "                    return player\n",
        "                # đường chéo lên phải\n",
        "                if r >= 3 and c <= self.cols - 4 and all(b[r-i][c+i] == player for i in range(4)):\n",
        "                    return player\n",
        "        return None\n",
        "\n",
        "    def print_board(self):\n",
        "        \"\"\"In bàn cờ\"\"\"\n",
        "        for row in self.board:\n",
        "            print(\" \".join(str(x) for x in row))\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "TWm5ELfKEb5j"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "board = ConnectFour(rows=6, cols=7)\n",
        "best_move, win_rate = monte_carlo_move(board, player=1, simulations_per_move=200)\n",
        "print(f\"Best first move for Red: column {best_move} with estimated win rate {win_rate:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUY-fX4hCl4i",
        "outputId": "b4dfdcd5-11db-4190-ea72-2bfff8b9b970"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Move 0: win rate = 0.500\n",
            "Move 1: win rate = 0.595\n",
            "Move 2: win rate = 0.550\n",
            "Move 3: win rate = 0.650\n",
            "Move 4: win rate = 0.620\n",
            "Move 5: win rate = 0.590\n",
            "Move 6: win rate = 0.540\n",
            "Best first move for Red: column 3 with estimated win rate 0.650\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}